import os
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
from tqdm import tqdm
import timm
from torch import nn
import config
from PIL import Image

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")
print(f"ì´ë¯¸ì§€ í¬ê¸°: {config.img_size}, ë°°ì¹˜ í¬ê¸°: {config.batch_size}")

# ------------------------------
# 1) ëª¨ë¸ ì •ì˜
# ------------------------------
class EfficientNetB0Model(nn.Module):
    def __init__(self, num_classes, pretrained=True):
        super().__init__()
        self.backbone = timm.create_model('efficientnet_b0', pretrained=pretrained)
        self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, num_classes)
    
    def forward(self, x):
        return self.backbone(x)

class SimpleCombinationLayer(nn.Module):
    def __init__(self, num_models, num_classes):
        super().__init__()
        self.combination_layer = nn.Linear(num_models * num_classes, num_classes)
        self.dropout = nn.Dropout(0.1)
    
    def forward(self, model_outputs):
        concatenated = torch.cat(model_outputs, dim=1)
        output = self.dropout(concatenated)
        return self.combination_layer(output)

# ------------------------------
# 2) Dataset ì •ì˜
# ------------------------------
class FineGrainChangeLabelDataset(Dataset):
    def __init__(self, root_dir, transform=None, is_test=False):
        self.root_dir = root_dir
        self.transform = transform
        self.is_test = is_test
        self.samples = []
        self.classes = []
        self.class_to_idx = {}

        if is_test:
            self.samples = sorted([
                os.path.join(root_dir, f)
                for f in os.listdir(root_dir)
                if f.lower().endswith('.jpg')
            ])
            return
        
        base_classes = sorted([
            d for d in os.listdir(root_dir)
            if os.path.isdir(os.path.join(root_dir, d))
        ])
        combined = []
        for base in base_classes:
            for pose in sorted(os.listdir(os.path.join(root_dir, base))):
                path = os.path.join(root_dir, base, pose)
                if os.path.isdir(path):
                    combined.append(f"{base}_{pose}")

        self.classes = combined
        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}

        for base in base_classes:
            for pose in sorted(os.listdir(os.path.join(root_dir, base))):
                pose_path = os.path.join(root_dir, base, pose)
                if not os.path.isdir(pose_path):
                    continue
                idx = self.class_to_idx[f"{base}_{pose}"]
                for fname in os.listdir(pose_path):
                    if not fname.lower().endswith('.jpg'):
                        continue
                    self.samples.append((os.path.join(pose_path, fname), idx))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        if self.is_test:
            path = self.samples[idx]
            img = Image.open(path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img, path
        
        path, label = self.samples[idx]
        img = Image.open(path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, label

# ------------------------------
# 3) DataLoader ì¤€ë¹„
# ------------------------------
val_transform = transforms.Compose([
    transforms.Resize((config.img_size, config.img_size)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# fine-grained í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
train_dataset_for_classes = FineGrainChangeLabelDataset(config.train_root, transform=None, is_test=False)
fine_grained_classes = train_dataset_for_classes.classes
num_fine_classes = len(fine_grained_classes)
print(f"Fine-grained í´ë˜ìŠ¤ ìˆ˜: {num_fine_classes}")
print(f"Fine-grained í´ë˜ìŠ¤ ì˜ˆì‹œ: {fine_grained_classes[:5]}")

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë”
test_dataset = FineGrainChangeLabelDataset(config.test_root, transform=val_transform, is_test=True)
test_loader = DataLoader(
    test_dataset,
    batch_size=config.batch_size,
    shuffle=False,
    num_workers=os.cpu_count() // 2,
    pin_memory=True
)
print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_dataset)}")

# ------------------------------
# 4) ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
# ------------------------------
checkpoint_dir = getattr(config, 'model_save_dir', './models')
model_paths = [
    os.path.join(checkpoint_dir, "EfficientNet-b0_Model_1_best_acc.pth"),
    os.path.join(checkpoint_dir, "EfficientNet-b0_Model_2_best_acc.pth")
]
combination_path = os.path.join(checkpoint_dir, "Adaptive_Combination_Layer_best.pth")

for path in model_paths + [combination_path]:
    if not os.path.isfile(path):
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")

print("ë¡œë“œí•  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸:")
for i, path in enumerate(model_paths, 1):
    print(f"  EfficientNet-b0 Model {i}: {path}")
print(f"  Combination Layer: {combination_path}")

# ------------------------------
# 5) ëª¨ë¸ ë¡œë“œ
# ------------------------------
print("\n--- ëª¨ë¸ ë¡œë“œ ì‹œì‘ ---")
base_models = []
for i, mp in enumerate(model_paths, 1):
    print(f"EfficientNet-b0 Model {i} ë¡œë”©...")
    m = EfficientNetB0Model(num_classes=num_fine_classes, pretrained=False)
    m.load_state_dict(torch.load(mp, map_location=device))
    m.to(device).eval()
    base_models.append(m)

print("Combination Layer ë¡œë”©...")
combination_model = SimpleCombinationLayer(num_models=len(base_models), num_classes=num_fine_classes)
combination_model.load_state_dict(torch.load(combination_path, map_location=device))
combination_model.to(device).eval()
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# ------------------------------
# 6) ì¶”ë¡  ìˆ˜í–‰
# ------------------------------
print("\n--- ì¶”ë¡  ì‹œì‘ ---")
all_image_paths = []
all_fine_probabilities = []

with torch.no_grad():
    for images, paths in tqdm(test_loader, desc="ì¶”ë¡  ì¤‘"):
        images = images.to(device, non_blocking=True)
        outputs = []
        for m in base_models:
            with torch.cuda.amp.autocast():
                outputs.append(m(images))
        with torch.cuda.amp.autocast():
            final_logits = combination_model(outputs)
        probs = F.softmax(final_logits, dim=1)
        for i in range(probs.size(0)):
            all_image_paths.append(paths[i])
            all_fine_probabilities.append(probs[i].cpu().numpy())
print("ì¶”ë¡  ì™„ë£Œ!")

# ------------------------------
# 7) ê²°ê³¼ ì €ì¥ (ìˆ˜ì •ëœ ë¶€ë¶„)
# ------------------------------
print("\n--- ê²°ê³¼ ì €ì¥ ì‹œì‘ ---")
# ì´ë¯¸ì§€ ID ì¶”ì¶œ
image_ids = [os.path.basename(p).split('.')[0] for p in all_image_paths]

# ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì—ì„œ í—¤ë” ìˆœì„œ ë¶ˆëŸ¬ì˜¤ê¸°
sample_df = pd.read_csv('./data/sample_submission.csv')
submission_columns = sample_df.columns.tolist()
print("ìƒ˜í”Œ ì œì¶œ í—¤ë”:", submission_columns)

# ì œì¶œìš© ë°ì´í„° êµ¬ì„± (ìˆ«ìí˜• ì¸ë±ìŠ¤ ë§¤í•‘)
submission_data = []
for img_id, probs in zip(image_ids, all_fine_probabilities):
    row = {'ID': img_id}
    for idx, prob in enumerate(probs):
        col = str(idx)
        row[col] = prob
    submission_data.append(row)

submission_df = pd.DataFrame(submission_data)
# ë¶€ì¡±í•œ ì»¬ëŸ¼(í´ë˜ìŠ¤)ì„ 0.0ìœ¼ë¡œ ì±„ìš°ê¸°
for c in submission_columns:
    if c not in submission_df.columns:
        submission_df[c] = 0.0

# ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
submission_df = submission_df[submission_columns]

# íŒŒì¼ ì €ì¥
output_path = './output/final_submission.csv'
os.makedirs(os.path.dirname(output_path), exist_ok=True)
submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')
print(f"â–¶ ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

# ------------------------------
# 8) ì˜ˆì¸¡ ìš”ì•½ (ì„ íƒ)
# ------------------------------
print("\n--- ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ ---")
preds = [fine_grained_classes[np.argmax(p)] for p in all_fine_probabilities]
unique, counts = np.unique(preds, return_counts=True)
for cls, cnt in zip(unique, counts):
    print(f"{cls}: {cnt}ê°œ ({cnt/len(preds)*100:.1f}%)")

# ------------------------------
# 9) ë©”ëª¨ë¦¬ ì •ë¦¬
# ------------------------------
print("\n--- ë©”ëª¨ë¦¬ ì •ë¦¬ ---")
for i, m in enumerate(base_models, 1):
    m.cpu()
    del m
    print(f"  âœ“ Base Model {i} ë©”ëª¨ë¦¬ í•´ì œ")
combination_model.cpu(); del combination_model
torch.cuda.empty_cache()
print("  âœ“ GPU ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")